---
title: 搭建电商搜索引擎
date: 2019-02-08 21:51:40
tags: 技术 深度学习 推荐系统
---
## 介绍做的一个电商的搜索引擎
使用elk作为后台架构，elastic提供搜索的接口，logstash作为mysql和elastic之间数据同步的桥梁

其实这个只是常用引擎的第一步，一般的搜索引擎为了提高用户的点击率，在得到所有相关的物品之后，会进一步输入到一个模型当中，包含了用户的使用行为等参数，最后根据用户可能的购买率进行排序。
参考wide&deep模型：https://zhuanlan.zhihu.com/p/29640272

## logstash配置
logstash的基本安装和配置可以参考logstash的文章
如何做数据同步参考这边文章
https://zhuanlan.zhihu.com/p/40177683

logstash 每次只同步更新一条数据的问题
https://stackoverflow.com/questions/41418060/logstash-is-indexing-only-one-row-of-select-query-from-mysql-to-elastic-search

配置的参数的官方文档：
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html

## 完整的logstash的配置
初始化时候的配置,logstash-es-mysql.conf
<!--more-->
```
input{
     stdin {
     }
     jdbc {
         jdbc_driver_library => "/home/elastic/mysql-connector/mysql-connector-java.jar"
         jdbc_driver_class => "com.mysql.jdbc.Driver"
         jdbc_connection_string => "jdbc:mysql://116.62.126.101:3306/manzuoTestENV?characterEncoding=utf8&useSSL=false"
         jdbc_user => "manzuo"
         jdbc_password => "password"
         jdbc_paging_enabled => "true"
         jdbc_page_size => "50000"
         schedule => "* * * * * "#配置为每一分钟都更新一次
         type => "jdbc"
         statement => "select * from `index_alllist`"
         #statement => "select itemId,title,title2,parameter,author from `index_alllist`"
         tracking_column => "itemId"
         tracking_column_type => "numeric"
         clean_run => true
       }
}

filter{
    json{
        source => "message"
        remove_field => ["message"]
    }
}
output{
     elasticsearch {
         hosts => ["http://47.75.156.162:9200"]
         index => "manzuo_list"
         document_type =>"items"
         document_id => "%{itemid}" #这里全用小写的itemid，很重要，和mysql的大小写不同，应为es字段全是小写的啦
      }
      stdout {
         codec => json_lines
     }
}
```
启动logstash:
./bin/logstash -f logstash-es-mysql.conf

启动之前首先创建索引，因为要使用中文的分词器
先安装中文分词器的插件
https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-smartcn.html
删除已有的索引(存在的话):
DELETE /manzuo_list
设置新索引的analyzer:
```
PUT /manzuo_list
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "default": {
            "type": "smartcn"
          }
        }
      }
    }
  }
}
```
启动logstash去同步数据:
./bin/logstash -f logstash-es-mysql.conf
搜索:
```
GET /manzuo_list/items/_search
{
    "query": {
        "match": {
          "title": "核桃"
        }
    }
}
```
参考中文教程
https://www.elastic.co/cn/blog/how-to-search-ch-jp-kr-part-1

## 存在的问题
这样的配置只能做到mysql中的新数据向es中去追加
一旦mysql删除了老数据，es并不会同步去删除
